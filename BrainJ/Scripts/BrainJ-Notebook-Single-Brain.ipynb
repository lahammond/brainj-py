{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba6078d",
   "metadata": {},
   "source": [
    "**BrainJ Single/Multi Brain Processing**\n",
    "\n",
    "- Currently expects registered sections from BrainJ ImageJ pipeline\n",
    "- Channels are enhanced using CARE networks trained on 1.6µm data and segmented using U-Nets and StarDist.\n",
    "- csv files of raw, transformed and mapped cells are generated in addition to optional intermediate images for data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab52bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have GPU access\n"
     ]
    }
   ],
   "source": [
    "#Add the BrainJ install directory to the path\n",
    "import sys\n",
    "sys.path.append('D:/Dropbox/Github/BrainJ-Python/')\n",
    "\n",
    "#import QLEAN modules\n",
    "from BrainJ.Environment import main, imgan\n",
    "\n",
    "#Settings for Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%gui qt\n",
    "# other options\n",
    "\n",
    "import matplotlib as plt\n",
    "plt.rcParams[\"figure.figsize\"]=20,20 # makes inline figures full width\n",
    "\n",
    "#Testing unet initalization and GPU access\n",
    "\n",
    "main.check_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dc891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing brain: D:/BrainJ Datasets/B4 Fast Test 1/\n"
     ]
    }
   ],
   "source": [
    "#%% Provide Brain dir\n",
    "\n",
    "brain_dir = \"D:/BrainJ Datasets/B4 Fast Test 1/\n",
    "\n",
    "print(\"Processing brain: \"+brain_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1584afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 registered sections to be processed.\n",
      "Processing section 1 of 1\n",
      "Restoring and segmenting channel 1...\n",
      "Restoration model =  D:/Dropbox/Github/BrainJ-Python/BrainJ/Models/647_Enhanced_Care_2D\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Section image shape:  (4395, 6771)\n",
      "Scale used:  1\n",
      "Restoring image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting cells...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "Restoring and segmenting channel 2...\n",
      "Restoration model =  D:/Dropbox/Github/BrainJ-Python/BrainJ/Models/Trap2_1_6um_widefield_resnet34_V2_2023_03_backbone_50epochs.hdf5\n",
      "Section image shape:  (4395, 6771)\n",
      "Scale used:  1\n",
      "Restoring image using loaded model...\n",
      "(4395, 6771) (4608, 6912) (18, 27, 256, 256)\n",
      "Detecting cells...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "Restoring and segmenting channel 3...\n",
      "Restoration model =  D:/Dropbox/Github/BrainJ-Python/BrainJ/Models/488_Enhanced_Care_2D\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Section image shape:  (4395, 6771)\n",
      "Scale used:  1\n",
      "Restoring image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting cells...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "Restoring and segmenting channel 4...\n",
      "Restoration model =  D:/Dropbox/Github/BrainJ-Python/BrainJ/Models/DAPI_Enhanced_Care_2D_V2\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Section image shape:  (4395, 6771)\n",
      "Scale used:  1\n",
      "Restoring image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting cells...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "Measuring channel 1...\n",
      "After filtering 16945 objects remain from total of 16958\n",
      "Measuring channel 2...\n",
      "After filtering 1887 objects remain from total of 1887\n",
      "Measuring channel 3...\n",
      "After filtering 20322 objects remain from total of 20331\n",
      "Measuring channel 4...\n",
      "After filtering 1444 objects remain from total of 1444\n",
      "Section processing time: 64.1 seconds.\n",
      "Time elased =  2 minutes. Estimated total time =  2 minutes.\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#Load in experiment parameters and analysis settings\n",
    "\n",
    "settings, locations = main.initialize_brainJ(brain_dir)\n",
    "\n",
    "#imgan.import_settings_and_locations(Settings, Locations)\n",
    "\n",
    "#%%\n",
    "#Modify specific parameters and settings:\n",
    "\n",
    "settings.save_intermediate_data = True\n",
    "locations.annotations_table = \"C:/Users/Luke_H/Desktop/BrainJ Atlas/ABA_CCF_25_2017/Atlas_Regions.csv\"\n",
    "\n",
    "#%%\n",
    "#restore and detect cells\n",
    "rawcells1, rawcells2, rawcells3, rawcells4 = imgan.cell_detection(settings, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3fdf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming cells processing time: 1.3 seconds.\n",
      "\n",
      "Transforming cells processing time: 1.1 seconds.\n",
      "\n",
      "Transforming cells processing time: 1.2 seconds.\n",
      "\n",
      "Transforming cells processing time: 1.1 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#transform cells\n",
    "transformedcells1, transformedcells2, transformedcells3, transformedcells4 = imgan.transform_cells(rawcells1, rawcells2, rawcells3, rawcells4, settings, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcb5df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating atlas region annotated count table for channel 1 ...\n",
      "Estimated time for annotating cells: 0.0 minutes.\n",
      "2 dataframes, which are approximately 8473 rows long, are being processed.\n",
      "6547 cells mapped into the brain.\n",
      "0 cells mapped out of the bounds of the atlas image. 10398 cells mapped outside of the brain.\n",
      "Annotating cells processing time: 9.8 seconds.\n",
      "\n",
      "Creating atlas region annotated count table for channel 2 ...\n",
      "Estimated time for annotating cells: 0.0 minutes.\n",
      "1 dataframes, which are approximately 1887 rows long, are being processed.\n",
      "975 cells mapped into the brain.\n",
      "1 cells mapped out of the bounds of the atlas image. 911 cells mapped outside of the brain.\n",
      "Annotating cells processing time: 0.8 seconds.\n",
      "\n",
      "Creating atlas region annotated count table for channel 3 ...\n",
      "Estimated time for annotating cells: 0.0 minutes.\n",
      "2 dataframes, which are approximately 10161 rows long, are being processed.\n",
      "9167 cells mapped into the brain.\n",
      "0 cells mapped out of the bounds of the atlas image. 11155 cells mapped outside of the brain.\n",
      "Annotating cells processing time: 12.0 seconds.\n",
      "\n",
      "Creating atlas region annotated count table for channel 4 ...\n",
      "Estimated time for annotating cells: 0.0 minutes.\n",
      "1 dataframes, which are approximately 1444 rows long, are being processed.\n",
      "518 cells mapped into the brain.\n",
      "1 cells mapped out of the bounds of the atlas image. 925 cells mapped outside of the brain.\n",
      "Annotating cells processing time: 0.7 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Annotate cells and create tables\n",
    "\n",
    "imgan.annotate_all_cells(transformedcells1, transformedcells2, transformedcells3, transformedcells4, settings, locations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a40b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainJ",
   "language": "python",
   "name": "brainj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
